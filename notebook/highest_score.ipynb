{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook follows the procedure of this URL:\n",
    "\n",
    "https://ahmedbesbes.com/how-to-score-08134-in-titanic-kaggle-challenge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train = pd.read_csv('input/train.csv')\n",
    "titanic_test = pd.read_csv('input/test.csv')\n",
    "data = pd.concat([titanic_train, titanic_test], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill few NaN\n",
    "data['Fare'].fillna(data['Fare'].mean(), inplace=True)\n",
    "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "### Name/Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_title = pd.Series([i.split(',')[1].split('.')[0].strip() for i in data['Name']])\n",
    "title_dic = {\n",
    "    \"Capt\": \"Officer\",\n",
    "    \"Col\": \"Officer\",\n",
    "    \"Major\": \"Officer\",\n",
    "    \"Jonkheer\": \"Royalty\",\n",
    "    \"Don\": \"Royalty\",\n",
    "    \"Sir\": \"Royalty\",\n",
    "    \"Dr\": \"Officer\",\n",
    "    \"Rev\": \"Officer\",\n",
    "    \"the Countess\":\"Royalty\",\n",
    "    \"Mme\": \"Mrs\",\n",
    "    \"Mlle\": \"Miss\",\n",
    "    \"Ms\": \"Mrs\",\n",
    "    \"Mr\": \"Mr\",\n",
    "    \"Mrs\": \"Mrs\",\n",
    "    \"Miss\": \"Miss\",\n",
    "    \"Master\": \"Master\",\n",
    "    \"Lady\": \"Royalty\",\n",
    "    'Dona': 'Royality'\n",
    "}\n",
    "data['Title'] = data_title.map(title_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FamilySize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['FSize'] = data['Parch'] + data['SibSp'] + 1\n",
    "\n",
    "data['Single'] = data['FSize'].map(lambda s: 1 if s == 1 else 0)\n",
    "data['SmallF'] = data['FSize'].map(lambda s: 1 if  s == 2  else 0)\n",
    "data['MedF'] = data['FSize'].map(lambda s: 1 if 2 <= s <= 4 else 0)\n",
    "data['LargeF'] = data['FSize'].map(lambda s: 1 if s >= 5 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1112: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "index_NaN_age = data['Age'][data['Age'].isnull()].index.values\n",
    "age_med = data['Age'].median()\n",
    "for i in index_NaN_age:\n",
    "    age_pred = data['Age'][((data['SibSp'] == data.iloc[i]['SibSp']) \n",
    "                            & (data['Parch'] == data.iloc[i]['Parch']) \n",
    "                            & (data['Pclass'] == data.iloc[i]['Pclass']))].median()\n",
    "    if not np.isnan(age_pred):\n",
    "        data.loc[i, 'Age'] = age_pred\n",
    "    else:\n",
    "        data.loc[i, 'Age'] = age_med"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item in data['Cabin'].iteritems():\n",
    "    if not pd.isnull(item):\n",
    "        data.loc[i, 'Cabin'] = item[0]\n",
    "    else:\n",
    "        data.loc[i, 'Cabin'] = 'X'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item in data['Ticket'].iteritems():\n",
    "    if not item.isdigit() :\n",
    "        data.loc[i, 'Ticket'] = item.replace(\".\",\"\").replace(\"/\",\"\").strip().split(' ')[0]\n",
    "    else:\n",
    "        data.loc[i, 'Ticket'] = 'X' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>FSize</th>\n",
       "      <th>Single</th>\n",
       "      <th>SmallF</th>\n",
       "      <th>MedF</th>\n",
       "      <th>LargeF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A5</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>X</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STONO2</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>X</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>X</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch  Ticket     Fare Cabin  \\\n",
       "0       0.0       3    male  22.0      1      0      A5   7.2500     X   \n",
       "1       1.0       1  female  38.0      1      0      PC  71.2833     C   \n",
       "2       1.0       3  female  26.0      0      0  STONO2   7.9250     X   \n",
       "3       1.0       1  female  35.0      1      0       X  53.1000     C   \n",
       "4       0.0       3    male  35.0      0      0       X   8.0500     X   \n",
       "\n",
       "  Embarked Title  FSize  Single  SmallF  MedF  LargeF  \n",
       "0        S    Mr      2       0       1     1       0  \n",
       "1        C   Mrs      2       0       1     1       0  \n",
       "2        S  Miss      1       1       0     0       0  \n",
       "3        S   Mrs      2       0       1     1       0  \n",
       "4        S    Mr      1       1       0     0       0  "
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_result(grid_search):\n",
    "    print(grid_search.best_params_)\n",
    "    print(grid_search.best_score_)\n",
    "\n",
    "data.drop(['PassengerId', 'Name'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding\n",
    "data[\"Sex\"] = data[\"Sex\"].map({\"male\": 0, \"female\":1})\n",
    "cols = ['Ticket', 'Cabin', 'Embarked', 'Title']\n",
    "\n",
    "# label-encoding\n",
    "data_label = data.copy()\n",
    "for col in cols:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    data_label[col] = le.fit_transform(data_label[col])\n",
    "    \n",
    "# one-hot encoding\n",
    "data_onehot = data.copy()\n",
    "for col in cols:\n",
    "    data_onehot = pd.get_dummies(data_onehot, columns=[col], prefix=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len(titanic_train)\n",
    "X_train_label = data_label[:train_len].drop('Survived', axis=1)\n",
    "Y_train_label = data_label[:train_len]['Survived'].copy()\n",
    "X_train_onehot = data_onehot[:train_len].drop('Survived', axis=1)\n",
    "Y_train_onehot = data_onehot[:train_len]['Survived'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'rf': ensemble.RandomForestClassifier(),\n",
    "    'ext': ensemble.ExtraTreesClassifier(),\n",
    "    'lgbm': lightgbm.LGBMClassifier(),\n",
    "    'svc': svm.SVC(probability=True)\n",
    "}\n",
    "\n",
    "grid_params = {\n",
    "    'rf': {\n",
    "        'max_depth' : range(3, 11),\n",
    "        'n_estimators': range(10, 51, 10),\n",
    "        'max_features': ['sqrt', 'auto', 'log2'],\n",
    "        'min_samples_split': range(2, 15),\n",
    "        'min_samples_leaf': range(1, 8),\n",
    "        'bootstrap': [True, False],\n",
    "    },\n",
    "    'ext': {\n",
    "        \"max_depth\": [None],\n",
    "        \"max_features\": [1, 3, 10],\n",
    "        \"min_samples_split\": range(2, 20, 3),\n",
    "        \"min_samples_leaf\": range(1, 10),\n",
    "        \"bootstrap\": [False],\n",
    "        \"n_estimators\" :[100, 200, 300],\n",
    "        \"criterion\": [\"gini\"]\n",
    "    },\n",
    "    'lgbm': {\n",
    "        'learning_rate': [1e-3, 1e-2, 1e-1], \n",
    "        'n_estimators':[100, 200],\n",
    "        'max_depth': [3, 4, 6, 8],\n",
    "        \"min_samples_split\": [30, 40],\n",
    "        'min_samples_leaf': [20, 20],\n",
    "        'max_features': [0.05, 0.1, 0.3],\n",
    "    },\n",
    "    '''\n",
    "    'svc': {\n",
    "        'kernel': ['rbf'], \n",
    "        'gamma': [ 0.001, 0.01, 0.1, 1],\n",
    "        'C': [1, 10, 50, 100, 200, 300, 1000],\n",
    "    }\n",
    "    '''\n",
    "}\n",
    "\n",
    "# Change here for the first run\n",
    "is_grid_search = {\n",
    "    'rf': False,\n",
    "    'ext': False,\n",
    "    'lgbm': False,\n",
    "    # 'svc': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_best = {}\n",
    "validation_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                       max_depth=10, max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=7, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.8406285072951739\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=None, max_features=3, max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=14,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "0.8282828282828283\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "               importance_type='split', learning_rate=0.1, max_depth=4,\n",
      "               max_features=0.05, min_child_samples=20, min_child_weight=0.001,\n",
      "               min_samples_leaf=20, min_samples_split=30, min_split_gain=0.0,\n",
      "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
      "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
      "0.8406285072951739\n",
      "SVC(C=50, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n",
      "0.7890011223344556\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    if is_grid_search[model]:\n",
    "        grid_search = model_selection.GridSearchCV(models[model], grid_params[model],\n",
    "                                                  scoring='accuracy', cv=5, n_jobs=8, iid='False')\n",
    "        grid_search.fit(X_train_label, Y_train_label)\n",
    "        estimator_best[model] = grid_search.best_estimator_\n",
    "        validation_scores[model] = grid_search.best_score_\n",
    "        \n",
    "    print(estimator_best[model])\n",
    "    print(validation_scores[model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = data_label[train_len:].drop('Survived', axis=1)\n",
    "test_onehot = data_onehot[train_len:].drop('Survived', axis=1)\n",
    "answer = pd.read_csv('answer.csv').drop('PassengerId', axis=1)\n",
    "answer = answer.rename(columns={'Survived': 'Answer'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf: Answer    0.787081\n",
      "dtype: float64\n",
      "ext: Answer    0.782297\n",
      "dtype: float64\n",
      "lgbm: Answer    0.76555\n",
      "dtype: float64\n",
      "svc: Answer    0.72488\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for name, clf in estimator_best.items():\n",
    "    pred = pd.Series(clf.predict(test_label), name='Survived', dtype=int)\n",
    "    print(name+':', answer[answer['Answer'] == pred].count()/answer['Answer'].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifer seems to get the best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.Series(estimator_best['rf'].predict(test_label), name='Survived', dtype=int)\n",
    "result = pd.concat([titanic_test['PassengerId'], pred], axis=1)\n",
    "result.to_csv('rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created simple ensemble model, but this does not improve the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer    0.787081\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "voting = ensemble.VotingClassifier(#estimators=estimator_best.items(), \n",
    "                                   estimators=[('rf', estimator_best['rf']), ('ext', estimator_best['ext'])],\n",
    "                                   voting='soft', n_jobs=8)\n",
    "voting.fit(X_train_label, Y_train_label)\n",
    "\n",
    "pred = pd.Series(voting.predict(test_label), name='Survived', dtype=int)\n",
    "print(answer[answer['Answer'] == pred].count()/answer['Answer'].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.Series(voting.predict(test_label), name='Survived', dtype=int)\n",
    "result = pd.concat([titanic_test['PassengerId'], pred], axis=1)\n",
    "result.to_csv('voting.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
